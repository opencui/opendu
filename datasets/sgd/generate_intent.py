#!/usr/bin/env python
# coding: utf-8

import json
import os
import sys
import gin
import random
from collections import defaultdict
from datasets import Dataset
import faiss
import time
from tqdm import tqdm
from sentence_transformers import SentenceTransformer
from sklearn.feature_extraction.text import TfidfVectorizer
import string
from transformers import AutoTokenizer, AutoModel
import torch
import pandas as pd
import faiss.contrib.torch_utils

# pip install -U gin-config faiss-cpu scikit-learn sentence-transformers
# python3 generate_intent.py --input=/home/sean/src/dstc8-schema-guided-dialogue/train/ --output=./res/train


@gin.configurable
class SgdDataset:
    def __init__(self, input, output,
                 stop_word_path,  # output path to save generated intent model examples'
                 fix_random_seed=True,  # 'use fixed random seed(for debug)'
                 pos_num=-1,  # 'num of positive sample num generated by each intent'
                 neg_num=-1,  # 'num of negative sample num generated by each intent'
                 training_percentage=1.0,  # 'percentage for training'
                 negative_proportions=1.0,  # 'how many negative examples to generate for each positive example'
                 dev_percentage=1.0,  # 'percentage for dev'
                 decode_method='transformer',  # 'embedding method for the sentence'
                 cover_filter=False,  # 'whether we use the cover_relation to filter the sentence'
                 random_generate=True):  # 'generating the utterance by replacing the slot name with slot val
        self.input = input
        self.output = output
        self.stop_word_path = stop_word_path
        self.fix_random_seed = True
        self.pos_num = pos_num
        self.neg_num = neg_num
        self.training_percentage = training_percentage
        self.negative_proportions = negative_proportions
        self.dev_percentage = dev_percentage
        self.decode_method = decode_method
        self.cover_filter = cover_filter
        self.random_generate = random_generate

    def label(self, pmodel="intents"):
        return f"{pmodel}_{self.decode_method}_random_{self.random_generate}_cover_{self.cover_filter}_pos_{self.pos_num}_neg_{self.neg_num}"


model = SentenceTransformer('multi-qa-MiniLM-L6-cos-v1')

MODEL = "intents"
TRAIN = "train"
TEST = "test"
DEV = "dev"


# This load the schema.
def load_description_dataset(base_path):
    intent_desc = defaultdict(list)
    with open(base_path + 'schema.json', encoding='utf-8') as f:
        f = json.load(f)

        for service in f:
            # in the "overall"   generate mode,only pick <service>_1  if there are multiple  services for one intent
            if service["service_name"][-1] != '1':
                continue
            service_name = service["service_name"]
            intents = service["intents"]
            for intent in intents:
                intent_name = intent['name']
                if intent_name in intent_desc.keys():
                    print(f"{intent_name} is repeated in {service_name}")
                intent_desc[intent_name] = intent["description"]
    results = pd.DataFrame({"source": intent_desc.keys(), "text": intent_desc.values()})
    results = Dataset.from_pandas(results)
    results = results.map(
        lambda x: {"embeddings": torch.nn.functional.normalize(encoder.convert([x["text"]])).detach().cpu().numpy()[0]}
    )

    results.add_faiss_index(column="embeddings")
    return results


def check_stop_words(slot_dict, utterance, string_list, stop_words_path):
    stop_words = []
    with open(stop_words_path, encoding='utf-8') as f:
        items = f.readlines()
        for t in items:
            stop_words.append(t.lower()[:-1])
    stop_words = set(stop_words)
    # print("stop_words",stop_words)
    single_dict = dict()
    if string_list:
        for key, values in slot_dict.items():
            for value in values:
                single_dict[value] = key
        string_list = sorted(string_list, key=lambda x: x[0])
        res_utterance = utterance[:string_list[0][0]]
        for i, (cur_start, cur_end) in enumerate(string_list):

            if i == len(string_list) - 1:
                res_utterance = res_utterance + utterance[cur_end:]
            else:
                res_utterance = res_utterance + utterance[cur_end:string_list[i + 1][0]]

    else:
        res_utterance = utterance
    punctuation_string = string.punctuation
    for i in punctuation_string:
        res_utterance = res_utterance.replace(i, '')

    all_not_slot_words = set(res_utterance.split())

    if len(all_not_slot_words - stop_words) >= 2:
        return True
    return False


def generate_expression_template(slot_dict, utterance, spans):
    '''
    replacing the slot val with the slot name,to avoid match the short slot val which may be included in other
    long slot val,we need sort by the length of the slot val
    '''
    if spans == []:
        return utterance
    single_dict = dict()

    for key, values in slot_dict.items():
        for value in values:
            single_dict[value] = key

    spans = sorted(spans, key=lambda x: x[0])
    res_utterance = utterance[:spans[0][0]]
    for i, (cur_start, cur_end) in enumerate(spans):
        # if len(string_list) >=2:
        #     print("sub string",utterance[cur_start:cur_end])
        res_utterance = res_utterance + ' < ' + single_dict[utterance[cur_start:cur_end]] + ' > '
        if i == len(spans) - 1:
            res_utterance = res_utterance + utterance[cur_end:]
        else:
            res_utterance = res_utterance + utterance[cur_end:spans[i + 1][0]]

    return res_utterance


class IntentMeta:
    """
    restore the all template of a certain intents, including the set of all possible exemplars,
    and the dict for all slot
    """

    def __init__(self, service):
        self.exemplars = dict()
        self.slot_dict = defaultdict(set)
        self.service = service
        self.dataset = None

    def add_sample(self, expression):
        expression_template = generate_expression_template(expression.slots, expression.utterance, expression.spans)
        if expression_template in self.exemplars:
            return

        expression.exemplar = expression_template
        for slot_name, slot_val_list in expression.slots.items():
            for slot_val in slot_val_list:
                self.slot_dict[slot_name].add(slot_val)
        self.exemplars[expression_template] = expression

    def generate_utterance(self, expression):
        expression_template = generate_expression_template(expression.slots, expression.utterance, expression.spans)
        for slot_name, slot_vals in self.slot_dict.items():
            if '< ' + slot_name + ' >' in expression_template:
                expression_template = expression_template.replace('< ' + slot_name + ' >', list(slot_vals)[random.randint(0, len(slot_vals) - 1)])
        return expression_template

    def finalize(self):
        source = []
        exemplars_list = []
        for exemplar, expression in self.exemplars.items():
            source.append(exemplar)
            exemplars_list.append(expression.tokenize_label())

        results = pd.DataFrame({"exemplar": source, "text": exemplars_list})
        results = Dataset.from_pandas(results)
        results = results.map(
            lambda x: {"embeddings": torch.nn.functional.normalize(encoder.convert([x["text"]])).detach().cpu().numpy()[0]}
        )

        results.add_faiss_index(column="embeddings")
        self.dataset = results


class Expression:
    """
    expression examples
    """

    def __init__(self, expression, intent, slots, string_list=None):
        self.utterance = expression
        self.intent = intent
        self.slots = slots  # dict to store slot, value pairs
        self.idx = None
        self.string_list = string_list
        self.exemplar = None
        self.service = None
        self.vague_slot_names = None

    def tokenize_label(self):
        no_underscore_utterance = self.exemplar
        for key, values in self.slots.items():
            no_underscore_utterance = no_underscore_utterance.replace(key, ' '.join(key.split('_')))
        return no_underscore_utterance


def cover_reaction(expression_A, expression_B):
    '''
    check if the slot of A could cover all slot of B
    '''
    return set(expression_B.slots.keys()).issubset(set(expression_A.slots.keys()))


def slot_val_to_slot_name(slot_dict, utterance):
    '''
    replacing the slot val with the slot name,to avoid match the short val which may be included
    in other long val,we need sort by the length of the slot val
    '''
    single_dict = dict()

    for key, values in slot_dict.items():
        for value in values:
            single_dict[value] = key

    single_dict = sorted(single_dict.items(), key=lambda x: len(x[0]), reverse=True)

    for (value, key) in single_dict:
        utterance = utterance.replace(value, '< ' + ' '.join(key.split('_')) + ' >')

    return utterance


def load_intent_meta(base_path):
    """
    load original sgd data and create expression examples
    :param base_path: input path to original sgd dataset
    :return: expression examples
    """
    intent_templates = defaultdict(IntentMeta)
    files = os.listdir(base_path)
    sentence_set = defaultdict(set)
    for file in files:
        if file[:6] != 'dialog':
            continue
        with open(base_path + file, encoding='utf-8') as f:
            f = json.load(f)
            for dialogue in f:
                turns = dialogue["turns"]
                pre_intents = set()
                for idx, turn in enumerate(turns):
                    if turn['speaker'] != 'USER':
                        continue
                    active_intents = set()
                    for frame in turn['frames']:
                        active_intents.add(frame['state']['active_intent'])

                    if idx - 1 >= 0 and turns[idx - 1]["frames"][0]["actions"][0]["act"] == "OFFER_INTENT":
                        check_intent = set(turns[idx - 1]["frames"][0]["actions"][0]["values"])
                    else:
                        check_intent = set()

                    if not (active_intents - pre_intents or (not pre_intents)):
                        continue

                    frame = turn['frames'][0]
                    if frame['service'][-1] == '1' and (
                            frame['state']['active_intent'] in active_intents - pre_intents) and \
                            frame['state']['active_intent'] != 'NONE' and \
                            frame['state']['active_intent'] not in check_intent:
                        string_list = []
                        utterance_slot = defaultdict(list)
                        for _slot in frame['slots']:
                            utterance_slot[_slot['slot']].append(turn['utterance'][_slot['start']:_slot['exclusive_end']].lower())
                            string_list.append((_slot['start'], _slot['exclusive_end']))

                        if not check_stop_words(utterance_slot, turn['utterance'].lower(), string_list, FLAGS.stop_word_path):
                            continue
                        expression = Expression(turn['utterance'].lower(), frame['state']['active_intent'], utterance_slot, string_list)
                        intent_templates[frame['state']['active_intent']].add_sample(expression)
                        sentence_set[frame['state']['active_intent']].add(expression.utterance)
                    pre_intents = active_intents
    return intent_templates


class SearchSimilarExpressions:
    """
    using sentence-transformer to encode all the utterance with new intent
    """

    def __init__(self, intent_expressions):
        self.expression_corpus = []  # expression corpus used to be encoded by bert for all expressions
        self.idx2expression = {}  # map idx to expression object
        self.intent_range = {}
        self.sentence_embeddings = None
        self.tfidf_matrix = None
        idx = 0
        stt = 0
        for intent, expressions in intent_expressions.items():
            end = len(expressions)
            # give the range of the expressions in the expression_corpus for every intent,  left closed right open
            self.intent_range[intent] = (stt, stt + end)
            stt += end
            for expression in expressions:
                self.expression_corpus.append(expression.utterance)

                expression.idx = idx
                # given the index for the order of the expression,idx indicates the order of the
                # sentence in the total expressions
                self.idx2expression[idx] = expression
                idx += 1

        idf_vectorizer = TfidfVectorizer(use_idf=True)
        self.tfidf_matrix = idf_vectorizer.fit_transform(self.expression_corpus).toarray()
        self.sentence_embeddings = model.encode(self.expression_corpus)


class IntentExample:
    def __init__(self, src, label, utterance, tokenized, exemplar=True):
        self.type = "intent"
        self.kind = "exemplar" if exemplar else "description"
        self.source = src
        self.label = label
        self.utterance = utterance
        self.exemplar = tokenized

    def toJSON(self):
        return json.dumps(self, default=lambda o: o.__dict__, sort_keys=True, indent=4)


def save(examples, path, label):
    """
    save generated examples into tsv files
    :param intent_examples:  generated examples
    :param path: output path
    :return: None
    """
    for key, examples in examples.items():
        # we only generate one file for each folder
        with open(os.path.join(path, label), 'w', encoding='utf-8') as f:
            for example in examples:
                f.write(json.dumps(example.toJson(), indent=4) + "\n")
    return


@gin.configurable
class ModelEncoder:
    def __init__(self, model_ckpt):
        self.device = "cuda:0" if torch.cuda.is_available() else "cpu"
        self.model = model_ckpt
        self.tokenizer = AutoTokenizer.from_pretrained(model_ckpt)
        self.model = AutoModel.from_pretrained(model_ckpt).to(self.device)

    def convert(self, text_list):
        encoded_input = self.tokenizer(text_list, padding=True, truncation=True, return_tensors="pt").to(self.device)
        encoded_input = {k: v for k, v in encoded_input.items()}
        return self.model(**encoded_input).last_hidden_state[:, 0]


def query(encoder, text, dataset, k=4):
    embedding = encoder.convert([text])[0].detach().cpu().numpy()
    scores, samples = dataset.get_nearest_examples("embeddings", embedding, k=k)
    samples_df = pd.DataFrame.from_dict(samples)
    samples_df["score"] = scores
    samples_df.sort_values("score", ascending=False, inplace=True)
    return samples_df


@gin.configurable
class GenerateIntentExamples:
    """
    generate examples from templates.
    """
    def __init__(self, encoder, training_percentage, negative_percentage, seed=None):
        if training_percentage < 0.0 or training_percentage > 1.0:
            raise ValueError("training_percentage is out of range")
        self.neg_percentage = negative_percentage
        self.training_percentage = training_percentage
        self.seed = seed
        self.desc_k = 8
        self.encoder = encoder
        self.pos_num = 16

    def __call__(self, templates, descriptions):
        examples = []
        random.seed(self.seed)
        starttime = time.time()

        for intent, meta in templates.items():
            # first create description related
            print(f"Handling {intent}")
            for exemplar, expression in meta.exemplars.items():
                utterance = meta.generate_utterance(expression)

                # Sample from description
                top_k_description = query(self.encoder, utterance, descriptions, k=8)
                for _, row in top_k_description.iterrows():
                    label = 1 if intent == row['source'] else 0
                    desc = row['text']
                    examples.append(IntentExample(intent, label, utterance, desc, False))

                # Sample from positive example
                pos_selection = random.sample(list(meta.exemplars.items()), self.pos_num)
                for lexemplar, lexpression in pos_selection:
                    if lexemplar == exemplar:
                        continue
                    tokenized = lexpression.tokenize_label()
                    examples.append(IntentExample(intent, 1, utterance, tokenized, True))

                # Sample from negative example:
                neg_examples = []
                for lintent, lmeta in templates.items():
                    if lintent == intent:
                        continue
                    top_k_negatives = query(self.encoder, utterance, lmeta.dataset, k=8)
                    for _, row in top_k_negatives.iterrows():
                        score = row['score']
                        tokenized = row["text"]
                        neg_examples.append((lintent, tokenized, score))
                neg_examples.sort(key=lambda x: x[2], reverse=True)
                for example in neg_examples[0:self.pos_num]:
                    examples.append(IntentExample(f"{intent}|{example[1]}", 0, utterance, example[1]))
        return examples


def generate_slot_index(base_path):
    slot_index = defaultdict(list)
    with open(base_path + 'schema.json', encoding='utf-8') as f:
        f = json.load(f)
        for service in f:
            # in the "overall"   generate mode,only pick <service>_1  if there are multiple  services for one intent
            if service["service_name"][-1]!= '1':
                continue

            for intent in service['intents']:
                slot_index[intent['name']] = []
                for name in intent['required_slots']:
                    for slot in service['slots']:
                        if slot['name'] == name:
                            slot_index[intent['name']].append(name)
                for name in intent['optional_slots'].keys():
                    for slot in service['slots']:
                        if slot['name'] == name:
                            slot_index[intent['name']].append(name)
                slot_index[intent['name']] = list(set(slot_index[intent['name']]))
    return slot_index


if __name__ == '__main__':
    gin.parse_config_file(sys.argv[1])

    FLAGS = SgdDataset()

    encoder = ModelEncoder()

    descriptions_dataset = load_description_dataset(FLAGS.input)

    templates = load_intent_meta(FLAGS.input)

    for key in templates:
        templates[key].finalize()

    # now we can create intent examples.
    build_intent_examples = GenerateIntentExamples(encoder)
    examples = build_intent_examples(templates, descriptions_dataset)
    print(len(examples))
    save(examples, FLAGS.output, FLAGS.label())
